# Kochæœºå™¨è‡‚å¼€å‘æ€»ç»“åŠå…¶ä½¿ç”¨æ‰‹å†Œ

## æºç å¾®è°ƒ

- é’ˆå¯¹ç›®å‰lerobotåˆ†æ”¯éœ€è¦è¿›è¡Œå¦‚ä¸‹çš„ä¿®æ”¹ï¼š

1ã€ åœ¨video_utils.pyæ–‡ä»¶å†…éƒ¨éœ€è¦ä¿®æ”¹torchcodecä¸ºpyavï¼Œå› ä¸ºè¿™æ˜¯è§†é¢‘ç¼–ç æ ¼å¼é—®é¢˜ï¼Œtorchcodecå®¹æ˜“å¯¼è‡´ä¸ç¨³å®šï¼Œæˆ‘ä»¬æ— è®ºå“ªç§æ–¹æ¡ˆéƒ½é€‰æ‹©ä½¿ç”¨ç¨³å®šçš„pyav

![image-20250813094305264](./pic/image-20250813094305264.png)

2ã€åœ¨camera_opencv.pyå°†å¤šä½™çš„éƒ¨åˆ†åˆ é™¤ï¼Œä¿ç•™self.index_or_path

![image-20250813094944219](./pic/image-20250813094944219.png)

3ã€åœ¨æ‰§è¡Œæ•°æ®é›†å½•åˆ¶çš„è¿‡ç¨‹ä¸­ä¼šå‡ºç°å› ä¸ºåŒè‡‚é€šä¿¡å­˜åœ¨å»¶è¿Ÿé—®é¢˜ï¼Œå¯¼è‡´ä¸»ã€ä»è‡‚è¿æ¥ä¸ä¸Šä»è€Œå¼•å‘å½•åˆ¶æ•°æ®é›†num_tryæ¬¡æ•°è¾¾åˆ°ä¸Šé™ï¼Œæ‰€ä»¥ä¿®æ”¹num_tryæ¬¡æ•°é¿å…æ•°æ®é›†å½•åˆ¶ä¸­æ–­ã€‚å…·ä½“æ­¥éª¤ä¸ºä¿®æ”¹koch_followerä¸­éƒ¨åˆ†ä»£ç é—®é¢˜

![image-20250813095752843](./pic/image-20250813095752843.png)

## åˆ©ç”¨è„šæœ¬ä½¿ç”¨lerobotæ¡†æ¶å†…éƒ¨çš„æœ‰å…³kochæœºå™¨è‡‚çš„ç›¸å…³ä»£ç 

- Kochæœºå™¨è‡‚æ ‡å®šéƒ¨åˆ†ä»£ç ä½¿ç”¨

ä½¿ç”¨çš„æ˜¯calibrateéƒ¨åˆ†çš„ä»£ç ï¼Œé€‰æ‹©å¥½ç›¸å¯¹åº”çš„ä¸»ä»æœºå™¨è‡‚ã€‚

```python
æ ‡å®šï¼š
python -m lerobot.calibrate --teleop.type=koch_leader --teleop.port=COM7 --teleop.id=my_leader

python -m lerobot.calibrate --robot.type=koch_follower --robot.port=COM4 --robot.id=my_follower
```

- å½•åˆ¶æ•°æ®é›†ç›¸å…³ä»£ç 

ä½¿ç”¨recordéƒ¨åˆ†çš„ä»£ç ï¼Œæ³¨æ„å‡ ä¸ªé—®é¢˜ï¼šç«¯å£åç§°ã€robot_idä¸ä¹‹å‰æ ‡å®šçš„æ—¶å€™ä¿æŒä¸€è‡´ï¼Œç›¸æœºçš„indexï¼Œå½•åˆ¶å‘¨æœŸæ•°ä»¥åŠå½•åˆ¶æ—¶é—´

```python
å½•åˆ¶æ•°æ®é›†ï¼š

python -m lerobot.record     --robot.type=koch_follower     --robot.port=COM4     --robot.id=my_follower     --robot.cameras="{ left: {type: opencv, index_or_path: 1, width: 640, height: 480, fps: 30, color_mode: 'rgb', rotation: 'NO_ROTATION'}, above: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, color_mode: 'rgb', rotation: 'NO_ROTATION'}}"     --teleop.type=koch_leader     --teleop.port=COM7     --teleop.id=my_leader     --display_data=true     --dataset.repo_id=renjielv030/training_datasets     --dataset.num_episodes=100     --dataset.episode_time_s=15     --dataset.reset_time_s=10     --dataset.single_task="Pick up the rectangular block and put it into the cup."     --dataset.push_to_hub=False    --dataset.root=D:\dataset_for_smolvla    --resume=false
```

- è®­ç»ƒä»£ç 

è¿™æ˜¯é’ˆå¯¹kochæœºå™¨è‡‚çš„è®­ç»ƒï¼Œé‡‡å–æ–¹æ³•ä¸ºVAæ¨¡å‹çš„ACTç®—æ³•ä»¥åŠå…¶å˜ç§ã€‚æ³¨æ„outputçš„ç›®å½•ï¼Œæ˜¯åœ¨è¿è¡Œç¨‹åºçš„å½“å‰ç›®å½•ï¼Œæˆ–è€…ç›´æ¥è®¾ç½®å…¶å›ºå®šè·¯å¾„ã€‚

```python
python -m lerobot.scripts.train   --policy.type=act   --policy.push_to_hub=false --dataset.root=H:/dataset_for_smolvla --dataset.repo_id=lizhuohang/block_cup_dataset_ACT   --batch_size=16   --steps=20000   --output_dir=outputs/train/my_koch_lzh   --job_name=my_kochACT_training --policy.device=cuda   --wandb.enable=false --policy.device=cuda
```

- è¯„ä¼°ã€çœŸæœºæ¼”ç¤ºä»£ç 

ä»¥ä¸‹æ˜¯é€šè¿‡ç¦»çº¿æ“ä½œå®ç°æ¥æ§åˆ¶æœºå™¨è‡‚kochä»è‡‚æ¥è¿›è¡Œè‡ªä¸»æ§åˆ¶ã€‚ğŸ’¥æ³¨æ„ç›¸æœºå‚æ•°çš„é…ç½®!!!! å½¢å‚å†…éƒ¨pathä¸ºæœ¬åœ°å­˜å‚¨è·¯å¾„ã€‚

```python
--robot.type=koch_follower
--robot.port=COM7
--robot.id=my_follower
--robot.cameras="{ left: { type: opencv, index_or_path: 1, width: 640, height: 480, fps: 30, color_mode: 'rgb', rotation: 'NO_ROTATION' }, above: { type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, color_mode: 'rgb', rotation: 'NO_ROTATION' } }"
--teleop.type=koch_leader
--teleop.port=COM8
--teleop.id=my_leader
--display_data=false
--dataset.reset_time_s=10
--dataset.single_task="Grab the purple rectangle and put it in the bowl."
--dataset.push_to_hub=False
--dataset.root=H:\eval_results\eval_purple_dataset_ACT_zj
--dataset.repo_id=renjielv030/eval_purple_dataset_ACT_zj
--dataset.num_episodes=3
--dataset.episode_time_s=100
--policy.path=H:\my_koch_lzh_zhangjiang\checkpoints\last\pretrained_model
```



è¿™æ˜¯é’ˆå¯¹kochæœºå™¨è‡‚é€‰æ‹©æŒ‡å®šç­–ç•¥ï¼Œå¦‚actç­–ç•¥è®­ç»ƒä¹‹åå¾—åˆ°çš„æ¨¡å‹æƒé‡æ¥è¿›è¡ŒçœŸæœºæ¼”ç¤ºæ“ä½œã€‚

## å‡ºç°çš„é”™è¯¯è§£æğŸ§¨ï¼š

- å…³äºè§£å†³draccusåº“ä¸‹æ”¯æŒçš„è¯»å†™æ–‡ä»¶çš„æƒé™çš„åŸå› åœ¨ä¸åŒçš„ç³»ç»Ÿä¸Šæœ‰ç€ä¸åŒçš„è¯»å†™æ–¹å¼ï¼Œåœ¨linuxå¯ä»¥æ”¯æŒå¯¹ä¸€ä¸ªæ–‡ä»¶åŒæ—¶è¿›è¡Œè¯»å†™ï¼Œä½†æ˜¯åœ¨windowsä¸‹é¢ä¸èƒ½å¯¹ä¸€ä¸ªæ–‡ä»¶åˆè¯»åˆå†™ï¼Œå†…éƒ¨æ“ä½œç³»ç»Ÿä¼šå¯¹æ–‡ä»¶è¿›è¡Œä¿æŠ¤ã€‚

  ```python
  File "D:\conda_config\envs\lerobotaloah\lib\site-packages\draccus\argparsing.py", line 104, in parse_args args, _ = self.parse_known_args(args, namespace, is_parse_args=True) File "D:\conda_config\envs\lerobotaloah\lib\site-packages\draccus\argparsing.py", line 138, in parse_known_args parsed_t = self._postprocessing(parsed_args) File "D:\conda_config\envs\lerobotaloah\lib\site-packages\draccus\argparsing.py", line 175, in _postprocessing with open(config_path, "r") as f: PermissionError: [Errno 13] Permission denied: 'C:\\Users\\æ­æ­\\Temp\\tmpzeronybn'
  ```

  æŠ¥é”™ç±»å‹å¦‚ä¸Šæ‰€å±•ç¤ºï¼š

  - âœ¨å°è¯•è¿‡çš„è§£å†³æ–¹æ¡ˆï¼š

    1ã€ ä¿®æ”¹æ–‡ä»¶æƒé™ï¼Œä¿®æ”¹å®Œå®Œå…¨æ§åˆ¶ï¼Œä½†æ˜¯ä¾ç„¶å‡ºç°é”™è¯¯âŒ

    2ã€ ä¿®æ”¹ç”¨æˆ·ç¯å¢ƒå˜é‡ï¼Œä¿®æ”¹è‡³Cç›˜ç›®å½•ä¸‹é¢ï¼Œè¿˜æ˜¯ä¼šå‡ºç°åŒæ ·çš„é”™è¯¯âŒ

    3ã€ä¿®æ”¹å…¶ä»–ç¯å¢ƒå˜é‡ä»¥åŠè¯»å†™é™åˆ¶ï¼Œè¿˜æ˜¯å‡ºç°é”™è¯¯âŒ

    âœ”ï¼šä¿®æ”¹draccusåº“åœ¨windowsä¸‹å¯¹äºæ–‡ä»¶çš„è¯»å†™æƒé™ï¼šåœ¨record.pyæ–‡ä»¶ä¸‹æ·»åŠ ä»¥ä¸‹ä»£ç ï¼š

    ```python
    # ä¿å­˜åŸå§‹æ–¹æ³•
    _orig_NTF = tempfile.NamedTemporaryFile
    
    def NamedTemporaryFile_windows(*args, **kwargs):
        # Windows ä¸‹å¼ºåˆ¶ delete=Falseï¼Œé¿å…é”æ–‡ä»¶
        kwargs['delete'] = False
        return _orig_NTF(*args, **kwargs)
    
    # è¦†ç›–æ‰
    tempfile.NamedTemporaryFile = NamedTemporaryFile_windows
    ```

    ä¾¿å¯ä»¥æ­£ç¡®åŠ è½½æœºå™¨è‡‚çš„ç›¸å…³é…ç½®ä¿¡æ¯å¹¶ä¸”èƒ½å¤ŸæˆåŠŸè¿è¡Œã€‚

## æ•°æ®é›†ç›¸å…³å®šä¹‰éƒ¨åˆ†

## ACTæ¨¡å‹åŠå…¶ç›¸å…³ä»‹ç»

### pushtæ•°æ®é›†

- metaæ•°æ®é›†çš„å†…å®¹

  1. episodes.jsons

     ææ–™é€‰å–è‡ªrecordéƒ¨åˆ†ï¼ŒåŒ…æ‹¬å½•åˆ¶æ•°æ®é›†é¢„è®­ç»ƒä»¥åŠ

     ```json
     {"episode_index": 0, "tasks": ["Push the T-shaped block onto the T-shaped target."], "length": 161}
     {"episode_index": 1, "tasks": ["Push the T-shaped block onto the T-shaped target."], "length": 118}
     ```

     | å­—æ®µå        | å«ä¹‰                                                         |
     | ------------- | ------------------------------------------------------------ |
     | episode_index | å½“å‰è®°å½•è¿™ä¸ªå‘¨æœŸçš„episodeç¼–å·ï¼Œè¿™é‡Œè®°å½•çš„ä¸ºç¬¬0ä¸ªepisode      |
     | tasks         | ä»»åŠ¡æè¿°ï¼Œæ˜¯ä¸€ä¸ªè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œç”¨äºè®­ç»ƒè¯­è¨€é©±åŠ¨çš„æœºå™¨äººæ§åˆ¶ï¼ˆæ¯”å¦‚é€šè¿‡LLMç†è§£ä»»åŠ¡ï¼‰ |
     | length        | è¿™ä¸ªepisodeåŒ…å«161å¸§/æ—¶é—´æ­¥ï¼Œæ¯ä¸€å¸§éƒ½æœ‰observationå’Œaction   |

  - `length` è¡¨ç¤ºæŸä¸€ä¸ª episodeï¼ˆä»»åŠ¡è¿‡ç¨‹ï¼‰ä¸­é‡‡é›†çš„**å¸§æ•°/æ—¶é—´æ­¥æ•°**ã€‚

    ä¹Ÿå°±æ˜¯æœºå™¨äººä»å¼€å§‹æ‰§è¡Œè¿™ä¸ªä»»åŠ¡ï¼Œåˆ°ç»“æŸï¼Œæ€»å…±è®°å½•äº†å¤šå°‘ä¸ª `(observation, action)` å¯¹ï¼Œç±»ä¼¼è¿™æ ·ï¼š

  - è¿™äº›æ•°æ®æ˜¯æ€ä¹ˆé‡‡é›†æ¥çš„ï¼Ÿè¿™äº›æ•°æ®å¤§å¤šæ˜¯é€šè¿‡å¦‚ä¸‹ **3ç§æ–¹å¼ä¹‹ä¸€**é‡‡é›†çš„ï¼š

    - **é¥æ“ä½œé‡‡é›†ï¼ˆTeleoperationï¼‰**

      äººé€šè¿‡é”®ç›˜/æ‰‹æŸ„/VR æ§åˆ¶çœŸå®æˆ–ä»¿çœŸçš„æœºæ¢°è‡‚æ“ä½œä»»åŠ¡ï¼Œå¹¶è®°å½•æ¯ä¸€æ­¥çš„çŠ¶æ€å’ŒåŠ¨ä½œã€‚

    - çŠ¶æ€ = observationï¼šå¦‚å›¾åƒå¸§ã€å…³èŠ‚ä½ç½®ç­‰
    - åŠ¨ä½œ = actionï¼šäººè¾“å…¥çš„æ§åˆ¶æŒ‡ä»¤ï¼ˆå¦‚æ¯ä¸ªç”µæœºçš„ç§»åŠ¨é‡ï¼‰

  - **è‡ªåŠ¨ç­–ç•¥é‡‡é›†ï¼ˆPolicy Collectionï¼‰**

    è®­ç»ƒå¥½çš„ç­–ç•¥è‡ªå·±å®Œæˆä»»åŠ¡ï¼Œæ¯æ¬¡è¿è¡Œæ—¶å°†æ•´ä¸ªè¿‡ç¨‹å½•ä¸‹æ¥ä½œä¸ºä¸€ä¸ª episodeã€‚

  -  **ä»¿çœŸç¯å¢ƒä¸­è„šæœ¬é‡‡é›†**
    - å†™ä¸€ä¸ªè„šæœ¬æˆ–è‡ªåŠ¨æ§åˆ¶å™¨ï¼Œæ§åˆ¶æœºå™¨äººåœ¨ä»¿çœŸç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡å¹¶è®°å½•ä¸‹æ¥ã€‚
    -  LeRobot/Pusht çœ‹èµ·æ¥æ›´åå‘ **ä»¿çœŸæ•°æ® + æ¨¡ä»¿å­¦ä¹ é‡‡é›†**ï¼Œæ•°æ®ä¹Ÿç”¨äºè®­ç»ƒ Transformer æ§åˆ¶ç­–ç•¥ã€‚

  2ï¼‰`info.json`:

  - `info.json` ä¸åŒ…å«å®é™…çš„è®­ç»ƒ/æ¼”ç¤ºæ•°æ®
  - å®ƒæ˜¯å¯¹ **æ‰€æœ‰æ•°æ®å­—æ®µçš„ç»“æ„ã€ç±»å‹å’Œå«ä¹‰** çš„ä¸€ä¸ªç»Ÿä¸€è¯´æ˜
  - åŠ è½½æ•°æ®ï¼ˆå¦‚ `.parquet`ï¼‰æ—¶ä¼šç”¨åˆ°å®ƒï¼Œæ¥æ­£ç¡®è§£é‡Šæ¯ä¸ªå­—æ®µ

  3ï¼‰`task.json`

  ```json
  {"task_index": 0, "task": "Push the T-shaped block onto the T-shaped target."}
  ```

  4ï¼‰`episodes_stats.jsonl`

  - è¿™æ®µ JSON æ•°æ®æ˜¯å¯¹æŸä¸ª episodeï¼ˆç¬¬ 204 æ¡ï¼‰**ç»Ÿè®¡ä¿¡æ¯ï¼ˆstatsï¼‰**çš„æ€»ç»“åˆ†æï¼Œä¹Ÿå°±æ˜¯å¯¹è¿™ä¸€æ®µäº¤äº’è¿‡ç¨‹é‡Œæ¯ä¸ªå­—æ®µçš„æ•´ä½“åˆ†å¸ƒåšäº†ä¸€ä¸ªæ•°æ®æè¿°ã€‚

- dataæ•°æ®

  - `episode_000000.parquet` `episode_000035.parquet` 

  | åˆ—å                  | å«ä¹‰                                                         |
  | --------------------- | ------------------------------------------------------------ |
  | **observation.state** | å½“å‰çŠ¶æ€å‘é‡ï¼ˆä¾‹å¦‚ï¼šç”µæœºçš„ä½ç½®/è§’åº¦ï¼‰ã€‚è¿™é‡Œæ˜¯ `[x, y]` å½¢å¼ï¼Œå¯èƒ½æ˜¯æŸä¸ªç‰©ä½“åœ¨å›¾åƒä¸­çš„åæ ‡ä½ç½®ã€‚ |
  | **action**            | æœºå™¨äººæ‰§è¡Œçš„åŠ¨ä½œã€‚é€šå¸¸æ˜¯æ§åˆ¶ä¿¡å·ï¼Œæ¯”å¦‚ç§»åŠ¨ç›®æ ‡çš„åç§»é‡æˆ–ç”µæœºè§’åº¦å˜æ›´ |
  | **episode_index**     | å½“å‰æ•°æ®å±äºç¬¬å‡ ä¸ª episodeï¼ˆç¬¬å‡ æ®µè½¨è¿¹ï¼‰                     |
  | **frame_index**       | å½“å‰æ˜¯è¯¥ episode ä¸­çš„ç¬¬å‡ å¸§ï¼ˆä» 0 å¼€å§‹ï¼‰                     |
  | **timestamp**         | æ—¶é—´æˆ³ï¼Œå•ä½ä¸ºç§’ï¼Œè¡¨ç¤ºè¯¥å¸§ç›¸å¯¹äº episode èµ·å§‹çš„æ—¶é—´          |
  | **next.reward**       | å½“å‰åŠ¨ä½œæ‰§è¡Œåï¼Œ**ä¸‹ä¸€å¸§ï¼ˆnextï¼‰**è·å¾—çš„å¥–åŠ±å€¼               |
  | **next.done**         | ä¸‹ä¸€å¸§æ˜¯å¦æ˜¯ episode çš„ç»“æŸå¸§                                |
  | **next.success**      | ä¸‹ä¸€å¸§æ˜¯å¦ä»»åŠ¡æˆåŠŸå®Œæˆ                                       |
  | **index**             | å½“å‰æ ·æœ¬åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­çš„ç´¢å¼•ç¼–å·ï¼ˆå…¨å±€å”¯ä¸€ï¼‰                 |
  | **task_index**        | å½“å‰å¸§å¯¹åº”çš„ä»»åŠ¡ç¼–å·ï¼ˆä»»åŠ¡è¯´æ˜è§ `tasks.jsonl`ï¼‰             |
  
- videosæ•°æ®é›†

  - `episode_000000.mp4` `episode_000030.mp4` 


3. LeRobot é¡¹ç›®å®šä¹‰çš„ **`LeRobotDataset` æ•°æ®é›†æ ¼å¼çš„å®˜æ–¹è¯´æ˜**ï¼Œè¿™ä¸ªæ ¼å¼æ˜¯ä¸ºäº†åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸æœºå™¨äººå­¦ä¹ ä»»åŠ¡ä¸­ï¼Œç»Ÿä¸€å¤„ç†è§†è§‰ã€åŠ¨ä½œã€çŠ¶æ€ç­‰ä¿¡æ¯è€Œè®¾è®¡çš„ã€‚

- `hf_dataset`ï¼šè¿™æ˜¯**ä¸»æ•°æ®è¡¨**ï¼ˆåŸºäº Hugging Face datasets åº“ï¼‰ï¼š æ¯æ¡æ•°æ®ä»£è¡¨ä¸€ä¸ª**æ—¶åˆ»å¸§**ï¼Œå­—æ®µä¸¾ä¾‹å¦‚ä¸‹ï¼š

  | å­—æ®µå                        | å«ä¹‰                               | ç±»å‹                   |
  | ----------------------------- | ---------------------------------- | ---------------------- |
  | `observation.images.cam_high` | å›¾åƒå¸§ï¼ˆmp4 è§†é¢‘ä¸­çš„æŸå¸§ï¼‰         | VideoFrameï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰ |
  | `observation.state`           | å½“å‰æœºå™¨äººçŠ¶æ€ï¼ˆå¦‚å…³èŠ‚è§’åº¦ã€ä½ç½®ï¼‰ | list[float32]          |
  | `action`                      | æœŸæœ›æ§åˆ¶ç›®æ ‡ï¼ˆå¦‚ç›®æ ‡å…³èŠ‚ä½ç½®ï¼‰     | list[float32]          |
  | `timestamp`                   | å½“å‰å¸§åœ¨è¯¥ episode ä¸­çš„æ—¶é—´        | float32                |
  | `episode_index`               | å½“å‰å¸§å±äºå“ªä¸ª episode             | int64                  |
  | `frame_index`                 | åœ¨è¯¥ episode ä¸­çš„å¸§ç¼–å·ï¼Œä» 0 å¼€å§‹ | int64                  |
  | `next.done`                   | è¿™ä¸€å¸§æ˜¯å¦æ˜¯ episode çš„æœ€åä¸€å¸§    | bool                   |
  | `index`                       | åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­çš„å…¨å±€ç´¢å¼•           | int64                  |

## ACTåŸç†ç®—æ³•æµç¨‹ä»‹ç»

ï¼ˆâš ï¸**æ³¨ï¼šä»¥ä¸‹æè¿°çš„å„æ•°æ®ç»´åº¦ä¸ä¸€å®šå¯¹ï¼Œä»£ç æ•´ç†æ¥è‡ªclaud3.7**ï¼‰

1. ACTä½œä¸ºæ–¯å¦ç¦æœ€æ–°çš„Mobile ALOHAç³»ç»Ÿçš„æœ€æ ¸å¿ƒçš„ç®—æ³•ï¼šAction Chunking with Transformerã€‚å®ƒä¸ºå•¥æ•ˆæœè¿™ä¹ˆå¥½ï¼Œå…¶å®ä¸»è¦çš„å°±æ˜¯Transformerç”Ÿæˆå¼ç®—æ³•ï¼Œåœ¨ACTä¸­ä¸»è¦ä½¿ç”¨çš„æ˜¯CVAEã€‚

2. é¦–å…ˆè¦æ¸…æ¥šAEã€VAEã€CVAEçš„æ¦‚å¿µï¼ŒBç«™æœ‰ç”šå¾ˆå¤šæ•™ç¨‹

3. æ•°æ®é›†ç›®å½•ç»“æ„åˆ†æ

   - `episodes` ç›®å½•ï¼šå­˜å‚¨æ¯ä¸ªäº¤äº’ç‰‡æ®µçš„PyTorchæ–‡ä»¶
   - `meta_data` ç›®å½•ï¼šåŒ…å«ç´¢å¼•å’Œç»Ÿè®¡ä¿¡æ¯
   - `train` ç›®å½•ï¼šArrowæ ¼å¼çš„è®­ç»ƒæ•°æ®
   - `videos` ç›®å½•ï¼šå½•åˆ¶çš„è§†é¢‘æ–‡ä»¶

4. ç›¸æœºæ ‡å®šæ–¹å¼**ç›¸æœºä¸æœºå™¨äººçš„ç©ºé—´å…³ç³»**ï¼š

   - ACTç®—æ³•ä¸éœ€è¦æ˜¾å¼çš„ç›¸æœºæ ‡å®šï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ–¹æ³•

   - ç³»ç»Ÿé€šè¿‡ç¤ºèŒƒæ•°æ®å­¦ä¹ ç›¸æœºè§†è§’ä¸æœºå™¨äººåŠ¨ä½œä¹‹é—´çš„æ˜ å°„å…³ç³»

   - åœ¨è®­ç»ƒæ•°æ®ä¸­ï¼Œæ¨¡å‹éšå¼å­¦ä¹ äº†ç›¸æœºè§†è§’ä¸­çš„ç‰©ä½“ä½ç½®ä¸æ‰€éœ€æœºå™¨äººåŠ¨ä½œä¹‹é—´çš„å…³ç³»

   - ACTé€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°è¿™ä¸€ç‚¹ï¼š

     é€šè¿‡ç¤ºèŒƒæ•°æ®å­¦ä¹ è§†è§‰-è¿åŠ¨æ˜ å°„ï¼šç¤ºèŒƒæ•°æ®åŒ…å«ç›¸æœºå›¾åƒå’Œå¯¹åº”çš„æœºå™¨äººå…³èŠ‚è§’åº¦

     æ¨¡å‹å­¦ä¹ äº†å°†è§†è§‰è§‚å¯Ÿç›´æ¥æ˜ å°„åˆ°å…³èŠ‚ç©ºé—´åŠ¨ä½œçš„èƒ½åŠ›

     è¿™é¿å…äº†æ˜¾å¼çš„åæ ‡ç³»è½¬æ¢å’Œé€†è¿åŠ¨å­¦è®¡ç®—

5. æ€»ç»“æ¥è¯´ï¼ŒACTç®—æ³•çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå®ƒä¸éœ€è¦æ˜¾å¼çš„ç›¸æœºæ ‡å®šæˆ–åæ ‡ç³»è½¬æ¢ï¼Œè€Œæ˜¯é€šè¿‡ç«¯åˆ°ç«¯å­¦ä¹ ç›´æ¥ä»åŸå§‹æ„ŸçŸ¥æ•°æ®åˆ°æ§åˆ¶å‘½ä»¤çš„æ˜ å°„ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ¨¡ä»¿äººç±»ç¤ºèŒƒçš„åŠ¨ä½œã€‚

6. ACT (Action Chunking Transformer) æ¨¡å‹çš„å®Œæ•´æ•°æ®å¤„ç†æµç¨‹å¦‚ä¸‹ï¼š

- 1ï¼‰è¾“å…¥æ•°æ®é¢„å¤„ç†ï¼š

  ```python
  # è¾“å…¥æ•°æ®å‡†å¤‡
  observation = robot.capture_observation()         # åŒ…å«ç›¸æœºå›¾åƒå’Œæœºå™¨äººçŠ¶æ€
  normalized_data = normalize_inputs(observation)   # æ•°æ®å½’ä¸€åŒ–å¤„ç†
  ```

  ```python
  {
      "observation": {
          "images": {
              "laptop": [T, H, W, 3], # Tä¸ªæ—¶é—´æ­¥çš„å›¾åƒåºåˆ—
              "phone": [T, H, W, 3]
          },
          "state": [T, state_dim] # Tä¸ªæ—¶é—´æ­¥çš„æœºå™¨äººçŠ¶æ€
      },
      "action": [T, action_dim] # Tä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œï¼ˆèˆµæœºå€¼ï¼‰
  }
  ```

  - observationæ•°æ®å¦‚ä¸‹(rerun.ioå±•ç¤ºå›¾çš„æ•°æ®å°±æ˜¯actionã€stateã€imageï¼Œå¯ä»¥å¯¹ç…§ä¸Šé¢å±•ç¤ºå›¾çœ‹)ï¼š

    - åœ¨æ—¶é—´æ­¥Tï¼Œæœ‰`observation.images.laptop[t]`ã€`observation.images.phone[t]`ã€`observation.state[t]`å’Œ`action[t]`

    - `observation.state[t]`ï¼šæ—¶é—´æ­¥tæ—¶follower armçš„å®é™…ä½ç½®
    - `action[t]`ï¼šæ—¶é—´æ­¥tæ—¶å‘é€ç»™follower armçš„ç›®æ ‡ä½ç½®ï¼ˆæ¥è‡ªleader armï¼‰


  - åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿™äº›æ•°æ®è¢«ç”¨æ¥ï¼š

    è®­ç»ƒè¾“å…¥ï¼š

    - ä½¿ç”¨observation.images[t]ï¼ˆç›¸æœºå›¾åƒï¼‰
    - ä½¿ç”¨observation.state[t]ï¼ˆæœºå™¨äººçŠ¶æ€ï¼‰

    è®­ç»ƒç›®æ ‡ï¼š

    - ä½¿ç”¨action[t]ä½œä¸ºæ¨¡å‹åº”è¯¥é¢„æµ‹çš„ç›®æ ‡


- 2ï¼‰è§†è§‰ç‰¹å¾æå–

```python
# å¤šç›¸æœºè§†è§‰ç‰¹å¾æå–
all_cam_features = []
all_cam_pos_embeds = []  # åŒæ—¶ä¿å­˜ä½ç½®ç¼–ç 

for camera_index in range(num_cameras):
    # ä»è¾“å…¥å›¾åƒæå–ç‰¹å¾
    image = normalized_data["observation.images"][:, camera_index]  # [B, 3, H, W]
    features = resnet_backbone(image)["feature_map"]                # [B, C, h, w]
    
    # ç”Ÿæˆä½ç½®ç¼–ç 
    pos_embed = sinusoidal_position_embedding(features)             # [B, C, h, w]
    
    # ç‰¹å¾æ˜ å°„è½¬æ¢
    cam_features = conv1x1(features)                                # [B, D, h, w]
    
    # åˆ†åˆ«ä¿å­˜ç‰¹å¾å’Œä½ç½®ç¼–ç 
    all_cam_features.append(cam_features)
    all_cam_pos_embeds.append(pos_embed)

# æ‹¼æ¥æ‰€æœ‰ç›¸æœºç‰¹å¾å’Œä½ç½®ç¼–ç 
vision_features = concat(all_cam_features, dim=-1)                  # [B, D, h, combined_w]
vision_pos_embeds = concat(all_cam_pos_embeds, dim=-1)              # [B, D, h, combined_w]

# è½¬æ¢ä¸ºåºåˆ—æ ¼å¼ï¼Œå³Transformerè¾“å…¥æ ¼å¼ï¼š[åºåˆ—é•¿åº¦, æ‰¹é‡å¤§å°, ç‰¹å¾ç»´åº¦]
vision_tokens = reshape(vision_features, "b d h w -> (h w) b d")    # [(h*w), B, D]
vision_pos_embeds = reshape(vision_pos_embeds, "b d h w -> (h w) b d")  # [(h*w), B, D]

# å°†è§†è§‰ç‰¹å¾å’Œå…¶ä»–ç‰¹å¾ä¸€èµ·æ·»åŠ åˆ°ç¼–ç å™¨è¾“å…¥
encoder_tokens.extend(vision_tokens)
encoder_pos_embeds.extend(vision_pos_embeds)  # ä½ç½®ç¼–ç ä¹Ÿä¸€åŒåŠ å…¥

# æœ€ç»ˆåœ¨Transformerç¼–ç å™¨ä¸­ä½¿ç”¨
encoder_output = transformer_encoder(
    encoder_tokens,
    pos_embed=encoder_pos_embeds  # è¿™é‡Œä¼ å…¥ä½ç½®ç¼–ç 
)
```

- 3ï¼‰VAEä»…å¤„ç†åŠ¨ä½œåºåˆ—

```python
# VAEç¼–ç å™¨æµç¨‹ (ä»…åœ¨è®­ç»ƒæ—¶ä½¿ç”¨)
# å‡†å¤‡VAEç¼–ç å™¨è¾“å…¥
cls_token = cls_embed_weight.repeat(batch_size, 1, 1)               # [B, 1, D]
state_token = linear_proj(observation["observation.state"])          # [B, 1, D]
action_tokens = linear_proj(observation["action"])                   # [B, seq_len, D]

# å°†æ‰€æœ‰tokenæ‹¼æ¥
vae_input = concat([cls_token, state_token, action_tokens], dim=1)  # [B, seq_len+2, D]
vae_input = add_positional_embedding(vae_input)                      # [B, seq_len+2, D]
vae_input = vae_input.permute(1, 0, 2)                               # [seq_len+2, B, D]

# VAEç¼–ç å™¨å‰å‘ä¼ æ’­
encoder_output = vae_encoder(vae_input)                              # [seq_len+2, B, D]
cls_output = encoder_output[0]                                       # [B, D]

# ç”Ÿæˆéšç©ºé—´åˆ†å¸ƒå‚æ•°
latent_params = linear_proj(cls_output)                              # [B, 2*latent_dim]
mu = latent_params[:, :latent_dim]                                   # [B, latent_dim]
log_sigma_x2 = latent_params[:, latent_dim:]                         # [B, latent_dim]

# é‡‡æ ·æ½œå˜é‡
z = mu + exp(log_sigma_x2/2) * random_normal(mu.shape)               # [B, latent_dim]
```

- åˆ†ç¦»çš„ç¼–ç å’Œè§£ç è·¯å¾„ï¼š

  VAEç¼–ç å™¨ï¼šstate + action â†’ æ½œå˜é‡z

  Transformeré˜¶æ®µï¼šz + state + images â†’ é¢„æµ‹action

- 4ï¼‰Transformerç¼–ç å™¨

```python
# å‡†å¤‡ç¼–ç å™¨è¾“å…¥
encoder_tokens = []

# æ·»åŠ æ½œå˜é‡token
latent_token = linear_proj(z)                                        # [B, D]
encoder_tokens.append(latent_token)                                  # [1, B, D]

# æ·»åŠ çŠ¶æ€token
if use_robot_state:
    state_token = linear_proj(observation["observation.state"])      # [B, D]
    encoder_tokens.append(state_token)                               # [1+1, B, D]

# æ·»åŠ ç¯å¢ƒçŠ¶æ€token (å¦‚æœæœ‰)ï¼Œæœ¬æ¬¡é‡‡é›†ä¸åŒ…æ‹¬ç¯å¢ƒçŠ¶æ€
if use_env_state:
    env_token = linear_proj(observation["observation.environment_state"])  # [B, D]
    encoder_tokens.append(env_token)                                 # [1, B, D]

# å°†è§†è§‰ç‰¹å¾æ·»åŠ åˆ°encoder tokens
encoder_tokens.extend(vision_tokens)                                 # [1+1+h*w, B, D]

# æ·»åŠ ä½ç½®ç¼–ç 
pos_embed = prepare_position_embeddings(encoder_tokens)              # [1+1+h*w, B, D]

# Transformerç¼–ç å™¨å‰å‘ä¼ æ’­
encoder_output = transformer_encoder(encoder_tokens, pos_embed)      # [1+1+h*w, B, D]
```

- æ·»åŠ ç¯å¢ƒçŠ¶æ€tokenï¼Œç¯å¢ƒçŠ¶æ€æ˜¯æŒ‡ï¼š

  ç¯å¢ƒä¸­çš„éæœºå™¨äººçŠ¶æ€ä¿¡æ¯

  é€šå¸¸æ˜¯ç¯å¢ƒä¸­ç‰©ä½“çš„ä½ç½®ã€æœå‘ã€ç‰©ç†å±æ€§ç­‰

  å¯èƒ½æ¥è‡ªå¤–éƒ¨ä¼ æ„Ÿå™¨æˆ–æ¨¡æ‹Ÿç¯å¢ƒ

- è¿™ä¸ªåŠŸèƒ½ä¸»è¦åœ¨ä»¥ä¸‹åœºæ™¯ä¸­ä½¿ç”¨ï¼š

  æ¨¡æ‹Ÿç¯å¢ƒï¼š

  - ä¾‹å¦‚MuJoCoã€Isaac Simç­‰ç‰©ç†æ¨¡æ‹Ÿå™¨

  - æ¨¡æ‹Ÿå™¨å¯ä»¥ç²¾ç¡®æä¾›æ‰€æœ‰ç‰©ä½“çš„ä½ç½®å’Œæœå‘

  æœ‰å¤–éƒ¨è·Ÿè¸ªç³»ç»Ÿçš„å®éªŒå®¤ï¼š

  - ä½¿ç”¨è¿åŠ¨æ•æ‰ç³»ç»Ÿï¼ˆå¦‚OptiTrackã€Viconï¼‰

  - è¿™äº›ç³»ç»Ÿå¯ä»¥ç²¾ç¡®è·Ÿè¸ªç¯å¢ƒä¸­çš„ç‰©ä½“

  å¤šæ¨¡æ€è®­ç»ƒï¼š

  - æœ‰æ—¶ç ”ç©¶äººå‘˜æƒ³æ¯”è¾ƒ"æœ‰ç¯å¢ƒçŠ¶æ€"å’Œ"æ— ç¯å¢ƒçŠ¶æ€"çš„æ€§èƒ½å·®å¼‚

  - è¿™éœ€è¦æ¨¡å‹æ¶æ„æ”¯æŒå¯é€‰çš„ç¯å¢ƒçŠ¶æ€è¾“å…¥

- 5ï¼‰Transformerè§£ç å™¨

```python
# å‡†å¤‡è§£ç å™¨è¾“å…¥ï¼Œç›¸å½“äºtransformerè§£ç å™¨çš„query
decoder_tokens = zeros(chunk_size, batch_size, dim_model)            # [chunk_size, B, D]
decoder_pos_embed = decoder_positional_embedding.weight              # [chunk_size, D]
decoder_pos_embed = decoder_pos_embed.unsqueeze(1).repeat(1, batch_size, 1)  # [chunk_size, B, D]

# Transformerè§£ç å™¨å‰å‘ä¼ æ’­
memory = encoder_output                                              # [1+1+h*w, B, D]
decoder_output = transformer_decoder(
    decoder_tokens,                                                  # [chunk_size, B, D]
    memory,                                                          # [1+1+h*w, B, D]
    tgt_pos=decoder_pos_embed,                                       # [chunk_size, B, D]
    memory_pos=pos_embed                                             # [1+1+h*w, B, D]
)                                                                    # [chunk_size, B, D]
```

- 6ï¼‰åŠ¨ä½œé¢„æµ‹å¤´

```python
# é¢„æµ‹åŠ¨ä½œåºåˆ—
decoder_output = decoder_output.transpose(0, 1)                      # [B, chunk_size, D]
predicted_actions = action_head(decoder_output)                      # [B, chunk_size, action_dim]

# åå½’ä¸€åŒ–è¾“å‡º
actions = unnormalize_outputs(predicted_actions)                     # [B, chunk_size, action_dim]
```

- 7ï¼‰è®­ç»ƒæŸå¤±è®¡ç®—

```python
# åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—æŸå¤±
# è®¡ç®—é‡å»ºæŸå¤±
l1_loss = masked_l1_loss(predicted_actions, target_actions)          # å¿½ç•¥paddingéƒ¨åˆ†

# å¦‚æœä½¿ç”¨VAEï¼Œè®¡ç®—KLæ•£åº¦æŸå¤±
if use_vae:
    kl_loss = -0.5 * sum(1 + log_sigma_x2 - mu^2 - exp(log_sigma_x2))
    total_loss = l1_loss + kl_weight * kl_loss
else:
    total_loss = l1_loss
```

- 8ï¼‰æ¨ç†æ—¶å€™çš„åŠ¨ä½œé€‰æ‹©

```python
# æ²¡æœ‰ä½¿ç”¨æ—¶é—´é›†æˆçš„ä»£ç ï¼Œæˆ‘ç›®å‰çš„æ¨ç†æ˜¯æ²¡æœ‰ä½¿ç”¨æ—¶é—´é›†æˆçš„
@torch.no_grad
def select_action(observation):
    # æ ‡å‡†åŒ–è¾“å…¥
    normalized_obs = normalize_inputs(observation)
    
    # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œè¿è¡Œæ¨¡å‹ç”Ÿæˆæ–°çš„åŠ¨ä½œåºåˆ—
    if action_queue.empty():
        # å‰å‘ä¼ æ’­ç”ŸæˆåŠ¨ä½œåºåˆ—
        actions = forward_pass(normalized_obs)                       # [B, chunk_size, action_dim]
        actions = unnormalize_outputs(actions)                       # [B, chunk_size, action_dim]
        
        # å°†é¢„æµ‹çš„åŠ¨ä½œåºåˆ—åŠ å…¥é˜Ÿåˆ—ï¼ˆåªå–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ ·æœ¬ï¼‰
        for i in range(n_action_steps):  # æ³¨æ„è¿™é‡Œæ˜¯n_action_steps
            action_queue.append(actions[0, i])  # æ³¨æ„è¿™é‡Œåªå–ç¬¬ä¸€ä¸ªæ ·æœ¬[0,i]
    
    # è¿”å›ä¸‹ä¸€ä¸ªåŠ¨ä½œ
    return action_queue.popleft()
```

9ï¼‰chunkçš„ç†è§£ï¼Œä»¥åŠæ—¶é—´é›†æˆçš„æ¦‚å¿µ

- ChunkæŒ‡çš„æ˜¯æ¨¡å‹ä¸€æ¬¡é¢„æµ‹çš„è¿ç»­åŠ¨ä½œåºåˆ—ã€‚ACTæ¨¡å‹ä¸æ˜¯æ¯æ¬¡åªé¢„æµ‹ä¸€ä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œï¼Œè€Œæ˜¯é¢„æµ‹ä¸€ä¸ª"å—"ï¼ˆchunkï¼‰çš„åŠ¨ä½œï¼Œè¿™ä¸ªå—åŒ…å«å¤šä¸ªè¿ç»­æ—¶é—´æ­¥çš„åŠ¨ä½œåºåˆ—ï¼Œè§£ç å™¨çš„ç»´åº¦decoder_tokensï¼š[chunk_size, B, D]ã€‚

- Chunkåœ¨è®­ç»ƒå’Œæ¨ç†ä¸­çš„åº”ç”¨

  è®­ç»ƒé˜¶æ®µï¼š

  - æ¨¡å‹å­¦ä¹ é¢„æµ‹é•¿åº¦ä¸ºchunk_sizeçš„åŠ¨ä½œåºåˆ—

  - ä¾‹å¦‚ï¼šå¦‚æœchunk_size=100ï¼Œæ¨¡å‹ä¼šåŒæ—¶é¢„æµ‹100ä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œ

  æ¨ç†é˜¶æ®µï¼š

  - æ¨¡å‹ä¸€æ¬¡ç”Ÿæˆchunk_sizeé•¿åº¦çš„åŠ¨ä½œåºåˆ—

  - è¿™äº›åŠ¨ä½œè¢«å­˜å…¥é˜Ÿåˆ—ï¼Œç„¶åé€æ­¥æ‰§è¡Œ

  - å½“é˜Ÿåˆ—ä¸ºç©ºæ—¶ï¼Œå†æ¬¡è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ–°çš„åŠ¨ä½œåºåˆ—

- å…³äºzçš„æ¥æºå’Œä½œç”¨

  - zçš„æ¥æºï¼šzæ˜¯ä»VAEç¼–ç å™¨ç”Ÿæˆçš„æ½œå˜é‡

    æ¶æ„å›¾ä¸­çš„zç¡®å®æ˜¯VAEç¼–ç å™¨è¾“å‡ºçš„

    ä»£ç ä¸­ä½¿ç”¨é‡å‚æ•°åŒ–æŠ€å·§é‡‡æ ·ï¼šz = mu + exp(log_sigma_x2/2) * random_normal(mu.shape)

  - zçš„ä½œç”¨ï¼š

    å¢åŠ æ¨¡å‹çš„éšæœºå¤šæ ·æ€§å’Œæ³›åŒ–èƒ½åŠ›

    ç¼–ç åŠ¨ä½œåºåˆ—çš„éšå«ç»“æ„ï¼Œè€Œä¸ä»…æ˜¯å•ä¸ªçŠ¶æ€åˆ°å•ä¸ªåŠ¨ä½œçš„æ˜ å°„

  - å°†åŠ¨ä½œåˆ†å¸ƒä»ç¡®å®šæ€§è½¬ä¸ºæ¦‚ç‡åˆ†å¸ƒ

    å¦‚æœz=0ï¼šæ¨¡å‹ä¼šé€€åŒ–ä¸ºç¡®å®šæ€§æ˜ å°„

    å¤±å»æ³›åŒ–åˆ°æ–°æƒ…å†µçš„èƒ½åŠ›

  - è°ƒæ•´KLæƒé‡ï¼šåœ¨é…ç½®ä¸­ä¿®æ”¹kl_weightï¼ˆé»˜è®¤ä¸º10.0ï¼‰

    å¢å¤§è¿™ä¸ªå€¼ä¼šå¼ºåˆ¶zåˆ†å¸ƒæ›´æ¥è¿‘æ ‡å‡†æ­£æ€åˆ†å¸ƒ

    å‡å°è¿™ä¸ªå€¼ä¼šå…è®¸zä¿ç•™æ›´å¤šä»»åŠ¡ç‰¹å®šä¿¡æ¯

- æ—¶é—´é›†æˆæœ€å‡†ç¡®çš„æè¿°åº”è¯¥æ˜¯ï¼š

  æ—¶é—´é›†æˆçš„æœ¬è´¨æ˜¯å¯¹"åŒä¸€ä¸ªå®é™…æ—¶åˆ»"çš„åŠ¨ä½œè¿›è¡Œå¤šæ¬¡é¢„æµ‹å¹¶é›†æˆï¼Œ

  å¦‚æœæˆ‘ä»¬å°†å®é™…æ‰§è¡Œçš„æ—¶åˆ»æ ‡è®°ä¸º[Tâ‚€, Tâ‚, Tâ‚‚, ...]ï¼š

  - åœ¨æ—¶åˆ»t=0ï¼Œæˆ‘ä»¬é¢„æµ‹äº†[Tâ‚€, Tâ‚, Tâ‚‚, ...Tâ‚‰â‚‰]çš„åŠ¨ä½œ

  - åœ¨æ—¶åˆ»t=1 (æ‰§è¡Œå®ŒTâ‚€å)ï¼Œæˆ‘ä»¬é¢„æµ‹äº†[Tâ‚, Tâ‚‚, Tâ‚ƒ, ...Tâ‚â‚€â‚€]çš„åŠ¨ä½œ

  - åœ¨æ—¶åˆ»t=2 (æ‰§è¡Œå®ŒTâ‚å)ï¼Œæˆ‘ä»¬é¢„æµ‹äº†[Tâ‚‚, Tâ‚ƒ, Tâ‚„, ...Tâ‚â‚€â‚]çš„åŠ¨ä½œ

  è®ºæ–‡ä¸­å›¾ä¸­é”™ä½çš„æ ¼å­å°±æ˜¯åœ¨è¡¨ç¤ºï¼š

  - å¯¹å®é™…æ—¶åˆ»Tâ‚‚çš„é¢„æµ‹åœ¨t=0æ—¶æ˜¯ç¬¬3ä¸ªä½ç½®

  - å¯¹å®é™…æ—¶åˆ»Tâ‚‚çš„é¢„æµ‹åœ¨t=1æ—¶æ˜¯ç¬¬2ä¸ªä½ç½®

  - å¯¹å®é™…æ—¶åˆ»Tâ‚‚çš„é¢„æµ‹åœ¨t=2æ—¶æ˜¯ç¬¬1ä¸ªä½ç½®

  é›†æˆå…¬å¼åº”è¯¥ç†è§£ä¸ºï¼šå¯¹å®é™…æ—¶åˆ»T_kçš„æœ€ç»ˆåŠ¨ä½œæ˜¯å¤šæ¬¡é¢„æµ‹çš„åŠ æƒå¹³å‡

- ç›®å‰æ¨ç†æ²¡æœ‰ä½¿ç”¨æ—¶é—´é›†æˆï¼Œå¦‚æœè¦ä½¿ç”¨éœ€è¦ä¿®æ”¹å¦‚ä¸‹é…ç½®ï¼š

  ```yaml
     # ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œè¿™æ˜¯è®­ç»ƒåç”Ÿæˆçš„é…ç½®æ–‡ä»¶ï¼Œæ¨ç†çš„æ—¶å€™ä¼šè‡ªåŠ¨åŠ è½½
     vi outputs/train/koch_clip_clay_bowl/checkpoints/last/pretrained_model/config.yaml
     
     # æ‰¾åˆ°å¹¶ä¿®æ”¹è¿™ä¸¤è¡Œ
     temporal_ensemble_momentum: null  # æ”¹ä¸º temporal_ensemble_coeff: 0.01
     n_action_steps: 100               # æ”¹ä¸º n_action_steps: 1
  ```

10ï¼‰æ¶æ„æ€»ç»“ï¼š

- è¾“å…¥æµï¼š

  ç›¸æœºå›¾åƒ â†’ å½’ä¸€åŒ– â†’ ResNetéª¨å¹²ç½‘ç»œ â†’ è§†è§‰ç‰¹å¾

  æœºå™¨äººçŠ¶æ€ â†’ å½’ä¸€åŒ– â†’ çº¿æ€§æŠ•å½± â†’ çŠ¶æ€ç‰¹å¾

- VAEç¼–ç å™¨ (è®­ç»ƒæ—¶):

  [CLS] + çŠ¶æ€ + åŠ¨ä½œåºåˆ— â†’ Transformerç¼–ç å™¨ â†’ éšç©ºé—´åˆ†å¸ƒ â†’ é‡‡æ ·æ½œå˜é‡z

- Transformerç¼–ç å™¨:

  æ½œå˜é‡ + çŠ¶æ€ + è§†è§‰ç‰¹å¾ â†’ å¤šå±‚è‡ªæ³¨æ„åŠ› â†’ ä¸Šä¸‹æ–‡ç¼–ç 

- Transformerè§£ç å™¨:

  ä½ç½®æŸ¥è¯¢ + ç¼–ç å™¨è®°å¿† â†’ äº¤å‰æ³¨æ„åŠ› â†’ åŠ¨ä½œåºåˆ—è¡¨ç¤º

- è¾“å‡ºæµ:

  è§£ç å™¨è¾“å‡º â†’ çº¿æ€§å±‚ â†’ åŠ¨ä½œé¢„æµ‹ â†’ åå½’ä¸€åŒ– â†’ æœºå™¨äººåŠ¨ä½œ

